RiftForged Compression Library: Design (LZ4 & Zstd)
1. Introduction
This document outlines the design for RiftCompress, a modular and high-performance compression library for the RiftForged ecosystem. Complementing the RiftEncrypt library, RiftCompress provides a standardized way to reduce data size before encryption and transmission, optimizing bandwidth and storage across components like RiftNet, RiftServer, and RiftShard. The library will initially support two popular compression algorithms: LZ4 (for extremely fast compression/decompression) and Zstandard (Zstd) (for high compression ratios).

2. Core Requirements
Modularity: The library will be designed to easily accommodate new compression algorithms in the future.

Algorithm Support: It will initially support LZ4 and Zstd.

Ease of Use: It will provide a simple compress and decompress API, abstracting the underlying library-specific details.

Performance: The implementation will focus on efficiency, leveraging the high-speed capabilities of the chosen libraries.

Flexibility: Developers can choose the compression algorithm that best fits their needs, balancing compression speed against compression ratio.

3. Architecture
The architecture will mirror the design of the RiftEncrypt library, promoting consistency across the RiftForged codebase. It will be centered around a Compressor class that uses a specific compression algorithm.

3.1. CompressionAlgorithm Interface
A CompressionAlgorithm abstract base class will define the common interface for all compression algorithms.

 Conceptual C++ Interface
class CompressionAlgorithm {
public:
    virtual ~CompressionAlgorithm() = default;

    // Compresses data
    virtual byte_vec compress(const byte_vec& data) = 0;

    // Decompresses data
    virtual byte_vec decompress(const byte_vec& compressed_data) = 0;
};

3.2. Algorithm Implementations
We will provide concrete implementations for LZ4 and Zstd.

LZ4Algorithm: Implements the CompressionAlgorithm interface using the liblz4 library. This is ideal for scenarios where compression and decompression speed are the highest priority.

ZstdAlgorithm: Implements the CompressionAlgorithm interface using the libzstd library. This is suited for cases where achieving a higher compression ratio is more important, such as for data at rest.

3.3. Compressor Class
The Compressor class will be the main entry point for developers, abstracting the specific algorithm being used.

 Conceptual C++ Class
class Compressor {
private:
    std::unique_ptr<CompressionAlgorithm> algorithm;

public:
    explicit Compressor(std::unique_ptr<CompressionAlgorithm> algo);

    byte_vec compress(const byte_vec& data);
    byte_vec decompress(const byte_vec& compressed_data);
};

This design allows application code to be written independently of the chosen compression method.

4. Data Format
The output of the compress method will be the raw compressed byte stream as generated by the underlying library. Unlike the encryption library, there is no standard container format that includes metadata.

Important: The application using this library will be responsible for knowing which algorithm was used to compress the data in order to decompress it. A common pattern is to prefix the data with a single byte identifier (e.g., 0x01 for LZ4, 0x02 for Zstd) before passing it to the encryption layer.

5. Usage Example (Conceptual C++)
#include "riftforged_compress.hpp"

// Assume these are defined
#include "riftforged_crypto.hpp"

// --- Some data to process ---
byte_vec original_data = get_large_packet_data();
byte_vec key = generate_key(crypto_aead_chacha20poly1305_ietf_KEYBYTES);


// --- Scenario 1: High-speed compression for network packets ---
auto lz4_algo = std::make_unique<LZ4Algorithm>();
Compressor lz4_compressor(std::move(lz4_algo));

// Compress -> Encrypt
byte_vec compressed_data = lz4_compressor.compress(original_data);
// Note: In a real app, you might add a 'type' byte here.

auto chacha_algo = std::make_unique<ChaCha20Poly1305Algorithm>(key);
Encryptor encryptor(std::move(chacha_algo));
byte_vec final_payload = encryptor.encrypt(compressed_data);

// ... send final_payload over RiftNet ...

// --- Scenario 2: High-ratio compression for storage ---
auto zstd_algo = std::make_unique<ZstdAlgorithm>();
Compressor zstd_compressor(std::move(zstd_algo));
byte_vec highly_compressed_data = zstd_compressor.compress(original_data);

// ... write highly_compressed_data to a file on RiftServer ...

6. Integration
The RiftCompress library is designed to be chained with the RiftEncrypt library. The typical workflow for sending data will be Compress then Encrypt. The reverse workflow for receiving data will be Decrypt then Decompress. This ensures that we are not trying to encrypt already compressed (and thus highly random) data, which is the correct cryptographic practice.